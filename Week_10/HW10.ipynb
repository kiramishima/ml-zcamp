{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework\n",
    "\n",
    "In this homework, we'll deploy the Bank Marketing model from the homework 5.\n",
    "We already have a docker image for this model - we'll use it for \n",
    "deploying the model to Kubernetes.\n",
    "\n",
    "\n",
    "## Building the image\n",
    "\n",
    "Clone the course repo if you haven't:\n",
    "\n",
    "```\n",
    "git clone https://github.com/DataTalksClub/machine-learning-zoomcamp.git\n",
    "```\n",
    "\n",
    "Go to the `course-zoomcamp/cohorts/2024/05-deployment/homework` folder and \n",
    "execute the following:\n",
    "\n",
    "\n",
    "```bash\n",
    "docker build -t zoomcamp-model:3.11.5-hw10 .\n",
    "```\n",
    "\n",
    "> **Note:** If you have troubles building the image, you can \n",
    "> use the image we built and published to docker hub:\n",
    "> `docker pull svizor/zoomcamp-model:3.11.5-hw10`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "Run it to test that it's working locally:\n",
    "\n",
    "```bash\n",
    "docker run -it --rm -p 9696:9696 zoomcamp-model:3.11.5-hw10\n",
    "```\n",
    "\n",
    "And in another terminal, execute `q6_test.py` file:\n",
    "\n",
    "```bash\n",
    "python q6_test.py\n",
    "```\n",
    "\n",
    "You should see this:\n",
    "\n",
    "```python\n",
    "{'has_subscribed': True, 'has_subscribed_probability': <value>}\n",
    "```\n",
    "\n",
    "Here `<value>` is the probability of getting a subscription. You need to choose the right one.\n",
    "\n",
    "* 0.287\n",
    "* 0.530\n",
    "* 0.757 <-\n",
    "* 0.960"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'has_subscribed': True, 'has_subscribed_probability': 0.756743795240796}\n"
     ]
    }
   ],
   "source": [
    "!python homework/q6_test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can stop the container running in Docker.\n",
    "\n",
    "\n",
    "## Installing `kubectl` and `kind`\n",
    "\n",
    "You need to install:\n",
    "\n",
    "* `kubectl` - https://kubernetes.io/docs/tasks/tools/ (you might already have it - check before installing)\n",
    "* `kind` - https://kind.sigs.k8s.io/docs/user/quick-start/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "What's the version of `kind` that you have? \n",
    "\n",
    "Use `kind --version` to find out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kind version 0.25.0\n"
     ]
    }
   ],
   "source": [
    "!kind --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a cluster\n",
    "\n",
    "Now let's create a cluster with `kind`:\n",
    "\n",
    "```bash\n",
    "kind create cluster\n",
    "```\n",
    "\n",
    "And check with `kubectl` that it was successfully created:\n",
    "\n",
    "```bash\n",
    "kubectl cluster-info\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "What's the smallest deployable computing unit that we can create and manage \n",
    "in Kubernetes (`kind` in our case)?\n",
    "\n",
    "* Node\n",
    "* Pod <-\n",
    "* Deployment\n",
    "* Service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "Now let's test if everything works. Use `kubectl` to get the list of running services.\n",
    "\n",
    "What's the `Type` of the service that is already running there?\n",
    "\n",
    "* NodePort\n",
    "* ClusterIP <-\n",
    "* ExternalName\n",
    "* LoadBalancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME         TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE\n",
      "kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   6m27s\n"
     ]
    }
   ],
   "source": [
    "!kubectl get services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "To be able to use the docker image we previously created (`zoomcamp-model:3.11.5-hw10`),\n",
    "we need to register it with `kind`.\n",
    "\n",
    "What's the command we need to run for that?\n",
    "\n",
    "* `kind create cluster`\n",
    "* `kind build node-image`\n",
    "* `kind load docker-image` <-\n",
    "* `kubectl apply`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Image: \"zoomcamp-model:3.11.5-hw10\" with ID \"sha256:65846b29a8f1b89402601168df80099f930b952f792990f2a873a17f14337572\" not yet present on node \"kind-control-plane\", loading...\n"
     ]
    }
   ],
   "source": [
    "!kind load docker-image zoomcamp-model:3.11.5-hw10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                 STATUS   ROLES           AGE     VERSION   INTERNAL-IP   EXTERNAL-IP   OS-IMAGE                         KERNEL-VERSION                       CONTAINER-RUNTIME\n",
      "kind-control-plane   Ready    control-plane   8m49s   v1.31.2   172.18.0.2    <none>        Debian GNU/Linux 12 (bookworm)   5.15.167.4-microsoft-standard-WSL2   containerd://1.7.18\n"
     ]
    }
   ],
   "source": [
    "!kubectl get nodes -o wide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "Now let's create a deployment config (e.g. `deployment.yaml`):\n",
    "\n",
    "```yaml\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: subscription\n",
    "spec:\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: subscription\n",
    "  replicas: 1\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: subscription\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: subscription\n",
    "        image: <Image>\n",
    "        resources:\n",
    "          requests:\n",
    "            memory: \"64Mi\"\n",
    "            cpu: \"100m\"            \n",
    "          limits:\n",
    "            memory: <Memory>\n",
    "            cpu: <CPU>\n",
    "        ports:\n",
    "        - containerPort: <Port>\n",
    "```\n",
    "\n",
    "Replace `<Image>`, `<Memory>`, `<CPU>`, `<Port>` with the correct values.\n",
    "\n",
    "What is the value for `<Port>`?\n",
    "\n",
    "Apply this deployment using the appropriate command and get a list of running Pods. \n",
    "You can see one running Pod."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of `<Port>` is `9696`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.apps/subscription created\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f deployment.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                            READY   STATUS    RESTARTS   AGE\n",
      "subscription-544b4f9664-chr4v   1/1     Running   0          12s\n"
     ]
    }
   ],
   "source": [
    "!kubectl get pods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7\n",
    "\n",
    "Let's create a service for this deployment (`service.yaml`):\n",
    "\n",
    "```yaml\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: <Service name>\n",
    "spec:\n",
    "  type: LoadBalancer\n",
    "  selector:\n",
    "    app: <???>\n",
    "  ports:\n",
    "  - port: 80\n",
    "    targetPort: <PORT>\n",
    "```\n",
    "\n",
    "Fill it in. What do we need to write instead of `<???>`?\n",
    "\n",
    "Apply this config file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The value of `<???>` is `subscription`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "service/subscription-service created\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f service.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                   TYPE           CLUSTER-IP    EXTERNAL-IP   PORT(S)        AGE\n",
      "kubernetes             ClusterIP      10.96.0.1     <none>        443/TCP        16m\n",
      "subscription-service   LoadBalancer   10.96.18.88   <pending>     80:32699/TCP   9s\n"
     ]
    }
   ],
   "source": [
    "!kubectl get services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the service\n",
    "\n",
    "We can test our service locally by forwarding the port 9696 on our computer \n",
    "to the port 80 on the service:\n",
    "\n",
    "```bash\n",
    "kubectl port-forward service/<Service name> 9696:80\n",
    "```\n",
    "\n",
    "Run `q6_test.py` (from the homework 5) once again to verify that everything is working. \n",
    "You should get the same result as in Question 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'has_subscribed': True, 'has_subscribed_probability': 0.756743795240796}\n"
     ]
    }
   ],
   "source": [
    "!python homework/q6_test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoscaling\n",
    "\n",
    "Now we're going to use a [HorizontalPodAutoscaler](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/) \n",
    "(HPA for short) that automatically updates a workload resource (such as our deployment), \n",
    "with the aim of automatically scaling the workload to match demand.\n",
    "\n",
    "Use the following command to create the HPA:\n",
    "\n",
    "```bash\n",
    "kubectl autoscale deployment subscription --name subscription-hpa --cpu-percent=20 --min=1 --max=3\n",
    "```\n",
    "\n",
    "You can check the current status of the new HPA by running:\n",
    "\n",
    "```bash\n",
    "kubectl get hpa\n",
    "```\n",
    "\n",
    "The output should be similar to the next:\n",
    "\n",
    "```bash\n",
    "NAME               REFERENCE                 TARGETS   MINPODS   MAXPODS   REPLICAS   AGE\n",
    "subscription-hpa   Deployment/subscription   1%/20%    1         3         1          27s\n",
    "```\n",
    "\n",
    "`TARGET` column shows the average CPU consumption across all the Pods controlled by the corresponding deployment.\n",
    "Current CPU consumption is about 0% as there are no clients sending requests to the server.\n",
    "> \n",
    ">Note: In case the HPA instance doesn't run properly, try to install the latest Metrics Server release \n",
    "> from the `components.yaml` manifest:\n",
    "> ```bash\n",
    "> kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml\n",
    ">```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "horizontalpodautoscaler.autoscaling/subscription-hpa autoscaled\n"
     ]
    }
   ],
   "source": [
    "!kubectl autoscale deployment subscription --name subscription-hpa --cpu-percent=20 --min=1 --max=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME               REFERENCE                 TARGETS              MINPODS   MAXPODS   REPLICAS   AGE\n",
      "subscription-hpa   Deployment/subscription   cpu: <unknown>/20%   1         3         1          5m34s\n"
     ]
    }
   ],
   "source": [
    "!kubectl get hpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "serviceaccount/metrics-server created\n",
      "clusterrole.rbac.authorization.k8s.io/system:aggregated-metrics-reader created\n",
      "clusterrole.rbac.authorization.k8s.io/system:metrics-server created\n",
      "rolebinding.rbac.authorization.k8s.io/metrics-server-auth-reader created\n",
      "clusterrolebinding.rbac.authorization.k8s.io/metrics-server:system:auth-delegator created\n",
      "clusterrolebinding.rbac.authorization.k8s.io/system:metrics-server created\n",
      "service/metrics-server created\n",
      "deployment.apps/metrics-server created\n",
      "apiservice.apiregistration.k8s.io/v1beta1.metrics.k8s.io created\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Increase the load\n",
    "\n",
    "Let's see how the autoscaler reacts to increasing the load. To do this, we can slightly modify the existing\n",
    "`q6_test.py` script by putting the operator that sends the request to the subscription service into a loop.\n",
    "\n",
    "```python\n",
    "while True:\n",
    "    sleep(0.1)\n",
    "    response = requests.post(url, json=client).json()\n",
    "    print(response)\n",
    "```\n",
    "\n",
    "Now you can run this script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8 (optional)\n",
    "\n",
    "Run `kubectl get hpa subscription-hpa --watch` command to monitor how the autoscaler performs. \n",
    "Within a minute or so, you should see the higher CPU load; and then - more replicas. \n",
    "What was the maximum amount of the replicas during this test?\n",
    "\n",
    "\n",
    "* 1\n",
    "* 2\n",
    "* 3 <-\n",
    "* 4\n",
    "\n",
    "> Note: It may take a few minutes to stabilize the number of replicas. Since the amount of load is not controlled \n",
    "> in any way it may happen that the final number of replicas will differ from initial."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
